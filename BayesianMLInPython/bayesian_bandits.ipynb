{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Bandits / Thompson Sampling\n",
    "\n",
    "### Bayes Rule\n",
    "$$p(\\theta|X) \\propto p(X|\\theta)p(\\theta)$$\n",
    "\n",
    "### Conjugate Priors\n",
    "In our example, consider\n",
    "$$X \\sim bernoulli(\\theta)$$\n",
    "\n",
    "Conjugate prior:\n",
    "$$\\theta \\sim Beta(\\alpha, \\beta) $$\n",
    "$$p(\\theta)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}$$\n",
    "\n",
    "Posterior:\n",
    "$$p(\\theta|X) \\propto \\theta^{\\alpha-1+\\Sigma_{i=1}^Nx_i}(1-\\theta)^{\\beta-1+\\Sigma_{i=1}^N(1-x_i)}$$\n",
    "which means\n",
    "$$\\theta|X \\sim Beta(\\alpha+\\Sigma_{i=1}^Nx_i, \\beta+N-\\Sigma_{i=1}^Nx_i)$$\n",
    "\n",
    "- No prior knowledge, use $Beta(1,1) = Uniform[0,1]$\n",
    "- With prior knowledge, for example CTR of ads are usually ~ 1% or 2%, then encode it into the prior\n",
    "\n",
    "### Update the posterior in practice:\n",
    "- In our code, we update our model every time a data point is collected (which is equivalent to N=1)\n",
    "- The posterior in one step becomes the prior in the next step\n",
    "\n",
    "### Picking the bandit\n",
    "- instead of using upper bound, we use a sampel drawn from posterior, this is called Thompson sampling\n",
    "\n",
    "\n",
    "### Pseudcode\n",
    "```python\n",
    "class Bandit:\n",
    "    def sample():\n",
    "        return beta(a,b).sample() # p_estimate \n",
    "    \n",
    "    def update():\n",
    "        a=..., b=...\n",
    "for n in range(NUM_TRIALS):\n",
    "    j = argmax([b.sample() for b in bandits])\n",
    "    x = bandit[j].pull()\n",
    "    bandits[j].update(x)\n",
    "```\n",
    "\n",
    "- Be greedy, but with respect to the sample from postriors rather than some statistic estimated from sample (UCB method)\n",
    "\n",
    "\n",
    "### Summary\n",
    "- Bayesian methods gives us tools to get the actual mean posterior\n",
    "- Thompson sampling: rank each bandit based on posterior sample, posterior is fat , explore more; when its skinny, explore less.\n",
    "- Allow us to leave suboptimal distributions \"fat\", can choose the optimal banidt more\n",
    "\n",
    "\n",
    "### Which Alg. should you choose?\n",
    "- Thompson sampling is usually the winner\n",
    "- Note in RL, we usually just use epsilon-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-506054b8d681>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-506054b8d681>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    import scipy.stats import beta\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats import beta\n",
    "NUM_TRIALS = 2000\n",
    "BANDIT_PROBABILITIES = [0.2, 0.5, 0.75]\n",
    "\n",
    "class Bandit:\n",
    "    def __init__(self, p):\n",
    "        # p is the true win rate of each bandit\n",
    "        self.p = p\n",
    "        self.a = \n",
    "        self.b\n",
    "        self.N = 0\n",
    "        \n",
    "    def pull(self):\n",
    "        return int(np.random.random() < self.p)\n",
    "\n",
    "    def sample():\n",
    "        \n",
    "    \n",
    "    def update(self, x):\n",
    "        # x is the data for the bandit, either 0 or 1\n",
    "        self.N += 1\n",
    "        self.p_estimate = x / self.N + (self.N-1) / self.N * self.p_estimate\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
